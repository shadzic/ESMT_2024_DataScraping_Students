{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abb51e6-e8ae-4cb3-a1b7-43706ea2d5f7",
   "metadata": {},
   "source": [
    "# 03 Homework\n",
    "Â© Copyright: 2024, Selma Hadzic, all rights reserved.\n",
    "\n",
    "#### Number of points: 15 (weights 15% in the final grade)\n",
    "\n",
    "\n",
    "1. Pull from the `ESMT_2024_DataScraping_Lectures` repository: you should get this `03_Homework` file\n",
    "2. Launch VS Code and open your working-folder\n",
    "3. Create a `Session_03` folder, in which you create another folder called `data`\n",
    "4. Copy paste the notebook `03_Homework` from the lectures repo to the working-folder. Copy the csv files `movies.csv` and `movies_metadata.csv` into the `working-folder/Session_03/data` directory.\n",
    "5. Do the exercises on 03_Homework in your working-folder\n",
    "6. Once you are finished, copy-Paste the notebook into `ESMT_2024_DataScraping_Students` folder in your computer\n",
    "8. Commit and push your homework in your branch before the deadline\n",
    "\n",
    "#### Deadline: October 21st 08:59 am CET\n",
    "\n",
    "#### Any missed deadline without justification to the Administration will result in 0 points for this homework.\n",
    "#### If the Github branch is not correctly named using the indicated format **LASTNAME_firstname**, then a penalty of -2 points will be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea70485-ebf4-460f-9030-e08b673127a2",
   "metadata": {},
   "source": [
    "## 1. Exploration and data cleaning (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c778b-c041-4c18-acc9-5186aef41c88",
   "metadata": {},
   "source": [
    "**1.1. Read the dataset `movies.csv` and visualise it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c158e75-df74-4241-9c7c-7b6cbaf27935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f705d-05ea-4af9-b40e-f5f3df582455",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"./data/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd4387-5671-4d41-9c03-663ffe0d3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head() # show first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7357647-fad3-483f-bdf8-d72c7c0d0ed5",
   "metadata": {},
   "source": [
    "**1.2 Display the size and the number of missing data points per column of the DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675b85b-5d7e-4bcb-a8b1-da8e59d050ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bd766-c8ca-47be-be3d-cb939f4fa1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2990509-31bf-45f1-bda1-f1c6116fe765",
   "metadata": {},
   "source": [
    "**1.3 Fill the NaN and replace the original dataset**\n",
    "- YEAR: 'Unknown'\n",
    "- GENRE: 'Unknown'\n",
    "- RATING: with the median value\n",
    "- VOTES: 0\n",
    "\n",
    "We leave the NaN of RunTime and Gross for now, as there is no straightforward way to fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8410d-5477-4ba7-8c83-1d9f241d2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy = movies.copy(deep = True) # work on copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8627d6a-faf1-4173-b30c-e22a04fdfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.fillna({'YEAR': 'Unknown', 'GENRE': 'Unknown', 'RATING': movies_copy.RATING.median(), 'VOTES': 0}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0a902-87b7-4c8d-8503-06b32ff01638",
   "metadata": {},
   "source": [
    "**1.4 Drop the duplicated rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfa8ef-101f-463a-b2a9-cbd65fba9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57744aba-ddb9-4738-a937-e0c64829b038",
   "metadata": {},
   "source": [
    "**1.5 Replace the columns names to make them all lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fb9c5-6d6d-4b10-a5c5-597a7e3213c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.columns = movies_copy.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4750a5-964b-4ad7-beb5-74935b5841e4",
   "metadata": {},
   "source": [
    "**1.6 Convert the `votes` column into a `float type`**\n",
    "\n",
    "*Hint: the U.K. and U.S. use a comma to separate groups of thousands. You might need to remove this comma first before converting the numbers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabfbe6-7e57-494b-a853-274b9c191187",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.votes = movies_copy.votes.str.replace(',', '') # remove comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839ee34-a984-4134-9b39-fec16b2f523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.votes = movies_copy.votes.astype(float) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581e6d2-7046-4db5-9300-73072f0e3c6d",
   "metadata": {},
   "source": [
    "## 2. Descriptive statistics (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e3799-dcb8-4b69-a18a-438a6c9bce64",
   "metadata": {},
   "source": [
    "**2.1 What is the average rating?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f35963-d581-4673-873c-718e2a3d49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.rating.mean() # 6.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e2420-45b8-4b9e-a289-8a8496f83bf0",
   "metadata": {},
   "source": [
    "**2.2 What is the maximum runtime?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659af824-504c-4ed4-863d-bac28f76d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.runtime.max() # 853min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0f4b9-7999-4455-a253-ea660288db77",
   "metadata": {},
   "source": [
    "2.3 Filter the dataset to show which movie/serie has the longest runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30493be7-1eea-4675-9bc8-38d8c5d9acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.loc[movies_copy.runtime == movies_copy.runtime.max(), ['movies', 'runtime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a367eb-d842-45a7-a48e-af0d7fcb77f0",
   "metadata": {},
   "source": [
    "2.4 Plot the histogram of runtimes, filtering on (0, 200) range with 200 bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e1799-6cc0-49ad-8e7e-e4c7e1e9efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.runtime.plot(kind='hist', title=\"Histogram of runtime\", range = (0, 200), bins = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d75e94-ce19-454b-9365-0ac37e468765",
   "metadata": {},
   "source": [
    "**2.5 What is the number of votes a movie needs to have, to be in the top 10% most voted film?**\n",
    "\n",
    "*Tip: the 90th quantile*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e49a5b6-9aa6-402a-b6e9-4941a56c7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy.votes.quantile(q = 0.9) # 22193.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff85744-7efb-4723-a145-f933af5d1232",
   "metadata": {},
   "source": [
    "## 3. Merging datasets (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af297a4-e487-490e-819c-0437d256a7ef",
   "metadata": {},
   "source": [
    "**Read `movies_metadata.csv` and assign it to a `df_meta` variable**\n",
    "\n",
    "**Create a `merge_df` DataFrame from an `inner join` between `df` and `df_meta`**\n",
    "\n",
    "*Hint: you need to find the right key to join on*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68a335-9f5c-42dc-b577-9ca7bf905dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_meta = pd.read_csv(\"./data/movies_metadata.csv\", low_memory = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d120a-5ac7-4a0e-b7e4-b0589f6efcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = movies_meta.merge(movies_copy, left_on = 'original_title', right_on = 'movies') # I assume df refers to the movies.csv data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScraping Environment",
   "language": "python",
   "name": "datascraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
