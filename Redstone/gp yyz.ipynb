{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec53c0a8-133a-4675-96cb-a540991f9b62",
   "metadata": {},
   "source": [
    "# Group Project: Grin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb776a2-81c0-462b-aa23-99d4ccb97d9b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3a689a-3cf0-4c7f-8087-235d52e91642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8629805c-1be5-4739-b5f3-1c5526c5f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use double quotes to assign your API key to private_api_key variable as a string\n",
    "# .env to prevent this\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\"./data/.env\")\n",
    "\n",
    "# Access the private API key\n",
    "private_api_key = os.getenv(\"METEOSTAT_PRIVATE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb22e00-3728-444d-9817-a1751a323ce9",
   "metadata": {},
   "source": [
    "# Access API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40d66bf-173b-4758-969a-9d7777b266a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the API keys\n",
    "meteostat_api_key = os.getenv(\"METEOSTAT_PRIVATE_KEY\")\n",
    "foursquare_api_key = os.getenv(\"FOUR_SQUARE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a08dab13-86da-4e45-a777-22fc54d24c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query weather data for a specific city from weather api\n",
    "def get_weather_data(city_name, lat, lon, alt=43, start='2023-10-21', end='2024-10-21'):\n",
    "    weather_api_url = \"https://meteostat.p.rapidapi.com/point/daily\"\n",
    "    weather_headers = {\n",
    "    'x-rapidapi-host': \"meteostat.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': meteostat_api_key\n",
    "}\n",
    "\n",
    "    params = {\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'alt': alt,\n",
    "        'start': start,\n",
    "        'end': end\n",
    "    }\n",
    "    \n",
    "    response = requests.get(weather_api_url, headers=weather_headers, params=params)\n",
    "\n",
    "    # Test response\n",
    "    if response.status_code == 200:\n",
    "        weather_data = response.json()\n",
    "        weather_df = pd.DataFrame(weather_data['data'])\n",
    "        weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "        return weather_df\n",
    "    else:\n",
    "        print(f\"Failed to retrieve weather data for {city_name}. Status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de176c8a-a4eb-439b-8c79-235711b82c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query places data for a specific city from places api\n",
    "def get_places_data(city_name, lat, lon, radius=1000):\n",
    "    places_url = f\"https://api.foursquare.com/v3/places/search?ll={lat},{lon}&radius={radius}\"\n",
    "    headers = {'Authorization': foursquare_api_key}\n",
    "    response = requests.get(places_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        places_data = response.json()\n",
    "        foursquare_data = []\n",
    "        for place in places_data['results']:\n",
    "            foursquare_data.append({\n",
    "                'fsq_id': place['fsq_id'],\n",
    "                'name': place['name'],\n",
    "                'category': place['categories'][0]['name'],\n",
    "                'latitude': place['geocodes']['main']['latitude'],\n",
    "                'longitude': place['geocodes']['main']['longitude'],\n",
    "                'address': place['location'].get('address', 'No address available'),\n",
    "                'locality': place['location'].get('locality', 'Unknown locality')\n",
    "            })\n",
    "        return pd.DataFrame(foursquare_data)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve places data for {city_name}. Status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63deddd-916b-4682-982e-0ea82bfd943e",
   "metadata": {},
   "source": [
    "# Simulate entire year's bike parking spots in Berlin, Frankfurt and Munich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201ccb2f-9373-4c61-9124-fea93d9d37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate random points for the simulation\n",
    "def generate_random_points(n_points, vehicle_type, lat_min, lat_max, lon_min, lon_max):\n",
    "    data = {\n",
    "        'latitude': np.random.uniform(lat_min, lat_max, n_points),\n",
    "        'longitude': np.random.uniform(lon_min, lon_max, n_points),\n",
    "        'vehicle_type': [vehicle_type] * n_points\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Introduce some missing values to simulate real-world data\n",
    "    missing_indices = random.sample(range(n_points), int(n_points * 0.1))  # 10% missing values\n",
    "    df.loc[missing_indices, 'vehicle_type'] = np.nan  # Missing vehicle type\n",
    "    df.loc[missing_indices[:int(len(missing_indices)/2)], 'latitude'] = np.nan  # Missing latitude\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a472351-5daa-420c-8fdb-e23e01b94ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the nearest place for a given vehicle point using foursquare api\n",
    "def find_nearest_place(vehicle_lat, vehicle_lon, places_df):\n",
    "    min_distance = float('inf')\n",
    "    nearest_place = None\n",
    "    \n",
    "    for idx, place in places_df.iterrows():\n",
    "        place_coords = (place['latitude'], place['longitude'])\n",
    "        vehicle_coords = (vehicle_lat, vehicle_lon)\n",
    "        \n",
    "        # Calculate distance\n",
    "        distance = geodesic(vehicle_coords, place_coords).meters\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_place = place\n",
    "            \n",
    "    return nearest_place, min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4008e3d4-2563-49a4-9d01-c9f252632250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run simulation\n",
    "def run_simulation(n_batches, batch_size, vehicle_type, city_name, weather_df, places_df, lat_min, lat_max, lon_min, lon_max):\n",
    "    all_batches_data = []\n",
    "\n",
    "    for batch_num in range(n_batches):\n",
    "        # Generate random points for the current batch within the city's coordinate range\n",
    "        vehicle_df = generate_random_points(batch_size, vehicle_type, lat_min, lat_max, lon_min, lon_max)\n",
    "        \n",
    "        # Shuffle the data to introduce randomness\n",
    "        vehicle_df = vehicle_df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # Fill missing data\n",
    "        vehicle_df['vehicle_type'] = vehicle_df['vehicle_type'].fillna('unknown')\n",
    "        vehicle_df['latitude'] = vehicle_df['latitude'].fillna(vehicle_df['latitude'].median())\n",
    "        vehicle_df['longitude'] = vehicle_df['longitude'].fillna(vehicle_df['longitude'].median())\n",
    "        \n",
    "        # Assign nearest places\n",
    "        vehicle_places_data = []\n",
    "        for idx, vehicle in vehicle_df.iterrows():\n",
    "            nearest_place, distance = find_nearest_place(vehicle['latitude'], vehicle['longitude'], places_df)\n",
    "            vehicle_places_data.append({\n",
    "                'city': city_name,\n",
    "                'latitude': vehicle['latitude'],\n",
    "                'longitude': vehicle['longitude'],\n",
    "                'vehicle_type': vehicle['vehicle_type'],\n",
    "                'nearest_place_name': nearest_place['name'] if nearest_place is not None else 'None',\n",
    "                'place_category': nearest_place['category'] if nearest_place is not None else 'None',\n",
    "                'distance_to_place': distance if nearest_place is not None else 'N/A'\n",
    "            })\n",
    "        \n",
    "        vehicle_places_df = pd.DataFrame(vehicle_places_data)\n",
    "        \n",
    "        # Assign the corresponding weather condition and date to each batch\n",
    "        if batch_num < len(weather_df):\n",
    "            weather_row = weather_df.iloc[batch_num]\n",
    "            vehicle_places_df['weather_date'] = weather_row['date']\n",
    "            vehicle_places_df['temperature'] = weather_row['tavg']\n",
    "            vehicle_places_df['precipitation'] = weather_row['prcp']\n",
    "            vehicle_places_df['wind_speed'] = weather_row['wspd']\n",
    "        else:\n",
    "            vehicle_places_df['weather_date'] = None\n",
    "            vehicle_places_df['temperature'] = None\n",
    "            vehicle_places_df['precipitation'] = None\n",
    "            vehicle_places_df['wind_speed'] = None\n",
    "        \n",
    "        # Append the batch data to the list\n",
    "        all_batches_data.append(vehicle_places_df)\n",
    "\n",
    "    # Concatenate all batch results into a single DataFrame\n",
    "    final_data = pd.concat(all_batches_data, ignore_index=True)\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54e2fcf-8ac1-451d-9246-fbf713d585a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for each city\n",
    "def run_simulation_for_cities():\n",
    "    cities = {\n",
    "        'Berlin': {'lat': 52.5244, 'lon': 13.4105, 'lat_min': 52.50, 'lat_max': 52.55, 'lon_min': 13.35, 'lon_max': 13.45},\n",
    "        'Frankfurt': {'lat': 50.1109, 'lon': 8.6821, 'lat_min': 50.10, 'lat_max': 50.12, 'lon_min': 8.66, 'lon_max': 8.70},\n",
    "        'Munich': {'lat': 48.1351, 'lon': 11.5820, 'lat_min': 48.12, 'lat_max': 48.15, 'lon_min': 11.55, 'lon_max': 11.60}\n",
    "    }\n",
    "    \n",
    "    all_city_data = []\n",
    "    \n",
    "    for city_name, city_info in cities.items():\n",
    "        print(f\"Running simulation for {city_name}...\")\n",
    "        \n",
    "        # Get weather and places data for the city\n",
    "        weather_df = get_weather_data(city_name, city_info['lat'], city_info['lon'])\n",
    "        places_df = get_places_data(city_name, city_info['lat'], city_info['lon'])\n",
    "        \n",
    "        # Run the simulation for the city with batch size of 10 and 366 batches\n",
    "        city_data = run_simulation(\n",
    "            n_batches=366, \n",
    "            batch_size=10, \n",
    "            vehicle_type='bike', \n",
    "            city_name=city_name, \n",
    "            weather_df=weather_df, \n",
    "            places_df=places_df,\n",
    "            lat_min=city_info['lat_min'], \n",
    "            lat_max=city_info['lat_max'], \n",
    "            lon_min=city_info['lon_min'], \n",
    "            lon_max=city_info['lon_max']\n",
    "        )\n",
    "        \n",
    "        all_city_data.append(city_data)\n",
    "    \n",
    "    # Combine all cities' data into one DataFrame\n",
    "    final_data = pd.concat(all_city_data, ignore_index=True)\n",
    "    \n",
    "    # Save the final DataFrame to a CSV file\n",
    "    final_data.to_csv('./data/final_vehicle_places_weather_data_all_cities.csv', index=False)\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66f318-ba9a-4e54-a711-3506d847744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for all cities and get the final combined data\n",
    "final_vehicle_places_weather_data = run_simulation_for_cities()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d2ddf-fbae-4469-8ff1-8531c345fe57",
   "metadata": {},
   "source": [
    "# Further Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887d45e-09c9-491d-9f93-b1c049af3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bike_sim = pd.read_csv('./data/final_vehicle_places_weather_data_all_cities.csv')\n",
    "\n",
    "# Regroup place_category\n",
    "bike_sim['place_category'] = bike_sim['place_category'].replace({\n",
    "    r'.*(Restaurant|Joint|Bistro|Steakhouse).*': 'Restaurant',\n",
    "    r'.*Bar.*': 'Bar',\n",
    "    r'.*(Café|Coffee Shop).*': 'Cafe and Tea House'\n",
    "}, regex=True)\n",
    "\n",
    "# Convert the 'weather_date' column to datetime format\n",
    "bike_sim['weather_date'] = pd.to_datetime(bike_sim['weather_date'])\n",
    "\n",
    "# Create a new column 'business_quarter'\n",
    "bike_sim['business_quarter'] = 'Q' + bike_sim['weather_date'].dt.quarter.astype(str)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "bike_sim.to_csv('./data/final_data_augmented.csv', index=False)\n",
    "\n",
    "bike_sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304efcb5-dd2f-4c33-94e8-03845eb32e3c",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a527884-cd75-46b7-ba5d-8b553ae6f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "viz_sim = pd.read_csv('./data/final_data_augmented.csv')\n",
    "\n",
    "# Clean the data by ignoring rows with unknown vehicle type\n",
    "bike_sim_clean = viz_sim[viz_sim['vehicle_type'] != 'unknown']\n",
    "\n",
    "# Group by place category and city, bike counts\n",
    "place_city_bike = bike_sim_clean.groupby(['place_category', 'city']).agg(\n",
    "    bike_count=('vehicle_type', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Plot 1: Bike distribution by place category and city\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=place_city_bike.sort_values(by='bike_count', ascending=False), \n",
    "            x='bike_count', y='place_category', hue='city')\n",
    "plt.title('Bike Distribution by Place Category')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298590c-4210-4ac9-8290-cbe813aaaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top 5 place categories by bike counts\n",
    "top_categories = place_city_bike.groupby('place_category')['bike_count'].sum().nlargest(5).index\n",
    "\n",
    "# Filter the data for the top categories and bike counts per nearest place name\n",
    "top_places = bike_sim_clean[bike_sim_clean['place_category'].isin(top_categories)]\n",
    "\n",
    "# Count bikes per nearest place name\n",
    "top_places_counts = top_places.groupby(['nearest_place_name', 'place_category', 'city']).agg(\n",
    "    bike_count=('vehicle_type', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Get the top 10 places across all top categories\n",
    "top_places_top10 = top_places_counts.nlargest(10, 'bike_count') \n",
    "\n",
    "# Calculate average wind speed and precipitation for these selected places\n",
    "avg_wind_precip = bike_sim_clean[bike_sim_clean['nearest_place_name'].isin(top_places_top10['nearest_place_name'])].groupby('nearest_place_name').agg(\n",
    "    avg_wind_speed=('wind_speed', 'mean'),\n",
    "    avg_precipitation=('precipitation', 'mean'),\n",
    "    city=('city', 'first')  # Keep city for coloring\n",
    ").reset_index()\n",
    "\n",
    "# Set thresholds: 8 m/s for wind speed and 5 mm for precipitation\n",
    "wind_speed_threshold = 8\n",
    "precipitation_threshold = 5\n",
    "\n",
    "# Plot 2: Average wind speed for top places\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(data=avg_wind_precip, x='nearest_place_name', y='avg_wind_speed', hue='city')\n",
    "plt.axhline(y=wind_speed_threshold, color='black', linestyle='--')\n",
    "plt.title('Average Wind Speed for Top 10 Places in Top 5 Categories')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Average Wind Speed (m/s)')\n",
    "plt.xticks(rotation=45, ha='right')  \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd138c12-56c4-46d7-8932-2ba4814f47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Average precipitation for top places\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(data=avg_wind_precip, x='nearest_place_name', y='avg_precipitation', hue='city')\n",
    "plt.axhline(y=precipitation_threshold, color='black', linestyle='--')\n",
    "plt.title('Average Precipitation for Top 10 Places in Top 5 Categories')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Average Precipitation (mm)')\n",
    "plt.xticks(rotation=45, ha='right')  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScraping Environment",
   "language": "python",
   "name": "datascraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
